{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decompose MOB data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply NMF or sICA factorization to MOB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.curdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configobj import ConfigObj\n",
    "import os, glob\n",
    "import numpy as np\n",
    "from regnmf import ImageAnalysisComponents as ia\n",
    "from scipy.spatial.distance import pdist\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = os.path.abspath(os.path.join(os.path.pardir, \"Soelter_et_al_raw_data\"))\n",
    "#basepath = os.path.join('/media/jan/BackupWork/Documents/NewAnalysis')\n",
    "datapath = os.path.join(basepath, 'MOBconverted') #where to get the data\n",
    "savepath = os.path.join(basepath, 'MOBdecomposed') #where to save decompostion\n",
    "savepath_vis = os.path.join(basepath, \"Vis\",\"Factorizations\") #where to save visualization of decomposition\n",
    "cfgfile = os.path.join(basepath, 'configfiles', 'decompose', 'nnmf_20_sm5_convex_negTimelowSP.ini') #'sica_200.ini') #\n",
    "datafile = 'sph_meas'#'ios_meas'\n",
    "response_window = (8,12) #define frames to calculate odor response; ios:(3,5) sph:(8,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals =  [ani for ani in os.listdir(datapath) if ('FRV' in ani)] #('FRV' not in ani)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performs NMF factorization according to config file. The sparsness parameter is choosen iterativly: First start with 'sparse_start' as initial guess. Sparseness will increase in steps of 'sparse_increase' until spatial component correlation of stimulus dependent components drops below 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_start = 0.1 #inital sparseness strength\n",
    "sparse_increase = 0.1 #sparsness increase\n",
    "redo = False# redo factorization if it already exists\n",
    "assert 'nnmf' in cfgfile\n",
    "\n",
    "for animal in animals:\n",
    "    \n",
    "    #load config\n",
    "    cfg = ConfigObj(cfgfile, unrepr=True)\n",
    "    \n",
    "    #check if computation is already performed\n",
    "    savelocation = os.path.join(savepath, animal)\n",
    "    savename_mask = os.path.splitext(os.path.basename(cfgfile))[0] + '_sp*_' + datafile + '.npy'\n",
    "    if os.path.exists(savelocation):\n",
    "        if len(glob.glob(os.path.join(savelocation, savename_mask)))>0 and not(redo):\n",
    "            print '%s already done'%animal\n",
    "            continue\n",
    "    else:\n",
    "        os.makedirs(savelocation)\n",
    "    \n",
    "    #load data\n",
    "    filename = os.path.join(datapath, animal, datafile)\n",
    "    ts = ia.TimeSeries()\n",
    "    try:\n",
    "        ts.load(filename)\n",
    "    except IOError:\n",
    "        print '!!! No data for animal %s !!!'%animal\n",
    "        continue\n",
    "    \n",
    "    # perform decomposition. increase sparseness until spatial component correlation is below 0.5\n",
    "    cor = 1\n",
    "    while cor>0.5:\n",
    "        # set sparsness level\n",
    "        if 'sparse_param' in cfg:\n",
    "            cfg['sparse_param'] += sparse_increase\n",
    "        else:\n",
    "            cfg['sparse_param'] = sparse_start\n",
    "        \n",
    "        # perform decomposition\n",
    "        decomposer = ia.NNMF(**cfg)\n",
    "        decomposition = decomposer(ts)\n",
    "        decomposition.base._series[np.isnan(decomposition.base._series)] = 0 #clear nans\n",
    "            \n",
    "        # calc spatial cor of stimulus driven components\n",
    "        signal = ia.TrialMean()(ia.CutOut(response_window)(decomposition))\n",
    "        mode_cor = ia.CalcStimulusDrive()(signal)\n",
    "        mask = mode_cor._series.squeeze()<0.5\n",
    "        if np.sum(mask) > 1: #if there are stimulus driven components  \n",
    "            selected_modes = ia.SelectObjects()(decomposition, mask)   \n",
    "            cor = np.nanmax(1-pdist(selected_modes.base._series, 'correlation'))\n",
    "        else:\n",
    "            cor = np.nanmax(1-pdist(decomposition.base._series, 'correlation'))\n",
    "    \n",
    "    #save results\n",
    "    savename = os.path.splitext(os.path.basename(cfgfile))[0] + '_sp%02d'%(cfg['sparse_param']*10)+'_'+datafile\n",
    "    decomposition.save(os.path.join(savelocation, savename))\n",
    "    print '%s done'%animal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sICA factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redo = True\n",
    "assert 'sica' in cfgfile\n",
    "\n",
    "for animal in animals:\n",
    "    \n",
    "    savelocation = os.path.join(savepath, animal)\n",
    "    savename = os.path.splitext(os.path.basename(cfgfile))[0] + '_' + datafile\n",
    "    if os.path.exists(savelocation):\n",
    "        if os.path.exists(os.path.join(savelocation, savename + '.npy')) and not(redo):\n",
    "            print '%s already done'%animal\n",
    "            continue\n",
    "    else:\n",
    "        os.makedirs(savelocation)\n",
    "        \n",
    "    filename = os.path.join(datapath, animal, datafile)\n",
    "    ts = ia.TimeSeries()\n",
    "    try:\n",
    "        ts.load(filename)\n",
    "    except IOError:\n",
    "        print '!!! No data for animal %s !!!'%animal\n",
    "        continue\n",
    "    cfg = ConfigObj(cfgfile, unrepr=True)\n",
    "        \n",
    "    # perform decomposition\n",
    "    decomposer = ia.sICA(**cfg)\n",
    "    decomposition = decomposer(ts)\n",
    "    decomposition.base._series[np.isnan(decomposition.base._series)] = 0 #clear nans\n",
    "   \n",
    "    decomposition.save(os.path.join(savelocation, savename))\n",
    "    print '%s done'%animal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot decomposition overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot decompositions for selected animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'sica_200_ios_meas'#'nnmf_200_sm2_convex_negTimelowSP_sp*_ios_meas'\n",
    "draw_sphrois = True\n",
    "animals = [ani for ani in os.listdir(savepath) if ('FRV' not in ani)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = np.ceil(len(animals)/5.)\n",
    "fig = plt.figure(figsize=(10, 1.5*int(rows)))\n",
    "plt.subplots_adjust(left=0.02, bottom=0.02, right=0.98, top=0.9)\n",
    "\n",
    "for ix, animal in enumerate(animals):\n",
    "    ax = fig.add_subplot(rows, 5, ix+1)\n",
    "    bg = Image.open(os.path.join(datapath, animal, 'bg.png'))\n",
    "    bg = bg.convert('L')\n",
    "    \n",
    "    mf = ia.TimeSeries()\n",
    "    filename = glob.glob(os.path.join(savepath, animal, method+'.npy'))\n",
    "    assert len(filename) == 1\n",
    "    filename = filename[0].split('.')[0]\n",
    "    mf.load(filename)\n",
    "    \n",
    "    bg = bg.resize(mf.base.shape[::-1])\n",
    "    bg = np.asarray(bg)\n",
    "    if mf.name.split('_')[1] == 'l':\n",
    "        bg = bg[::-1]    \n",
    "       \n",
    "    mf = ia.TrialMean()(ia.CutOut(response_window)(mf))\n",
    "    t2t = ia.CalcStimulusDrive()(mf)._series.squeeze()\n",
    "    \n",
    "    myextent = np.array([0, mf.base.shape[1], mf.base.shape[0], 0])-0.5\n",
    "    ax.imshow(bg, interpolation='none', extent=myextent, cmap=plt.cm.bone)\n",
    "    for ix, base in enumerate(mf.base.shaped2D()):\n",
    "        mycolors = ['c', 'b'] if t2t[ix] <0.4 else ['0.3', '0.7']\n",
    "        if mf.name.split('_')[1] == 'l':\n",
    "            base  = base[::-1]    \n",
    "        ax.contourf(base, [0.3,0.7,1], colors=mycolors, alpha=0.5)\n",
    "    \n",
    "    #show rois\n",
    "    roi_path = os.path.join(datapath, animal, 'rois')\n",
    "    if draw_sphrois and os.path.exists(roi_path+'.npy'):\n",
    "        rois = ia.TimeSeries()\n",
    "        rois.load(roi_path)\n",
    "        for roi in rois.shaped2D():\n",
    "            if mf.name.split('_')[1] == 'l':\n",
    "                roi = roi[::-1]\n",
    "            ax.contour(roi, [0.5], colors=['w'], lw=2)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(animal, size=8)\n",
    "    \n",
    "fig.savefig(os.path.join(savepath_vis, method+'.pdf'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
