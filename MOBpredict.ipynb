{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Chemical space of odor spectra: Predict and Compare"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('/home/jan/Dokumente/Code/FUImaging/')\n",
      "sys.path.append('/home/jan/Dokumente/Code/BootstrapPrediction/')\n",
      "\n",
      "import ImageAnalysisComponents as ia\n",
      "import datastructures as ds\n",
      "import bootstrap_predictor as bp\n",
      "reload(bp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "<module 'bootstrap_predictor' from '/home/jan/Dokumente/Code/BootstrapPrediction/bootstrap_predictor.pyc'>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import glob, csv, json, os, pickle, copy\n",
      "import logging\n",
      "import matplotlib\n",
      "\n",
      "import numpy as np\n",
      "import pylab as plt\n",
      "\n",
      "from scipy.spatial.distance import pdist, squareform\n",
      "from collections import defaultdict\n",
      "from sklearn.svm import SVR, NuSVR\n",
      "from sklearn.ensemble import RandomForestRegressor \n",
      "from sklearn.feature_selection import SelectKBest, f_classif\n",
      "from sklearn.manifold import MDS\n",
      "from sklearn.isotonic import IsotonicRegression\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.metrics import r2_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Set level of output messages"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logger = logging.getLogger()\n",
      "logger.setLevel('WARNING') #'DEBUG','INFO', 'WARNING'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Define Helper Functions"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Functions to calculate EVA descriptor"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def _gaussian(x, mu, sigma):\n",
      "    return 1 / (sigma * np.sqrt(2 * np.pi)) * np.exp(-0.5 * ((x-mu)/float(sigma))**2)\n",
      "\n",
      "def _sum_of_gaussians(x_range, positions, heights, sigma):\n",
      "    assert len(positions) == len(heights)\n",
      "    return [np.sum(heights * _gaussian(x, positions, sigma)) for x in x_range]\n",
      "\n",
      "def calc_eva(spectra, spec_type='pure', kernel_width=10, bin_width=10, BFS_max=4000):\n",
      "    \"\"\" sum of gaussians, sampled at regular intervals \"\"\"\n",
      "    x_range = np.arange(0, BFS_max, bin_width)\n",
      "    features, molnames = [], []\n",
      "    for molid, spectrum in spectra.items():\n",
      "        # remove negative vibrations (result of imaginary frequencies)\n",
      "        valid_freqs = spectrum['freq'][spectrum['freq'] > 0]\n",
      "        intensities = spectrum[spec_type] if (spec_type != 'pure') else np.ones(len(spectrum['freq']))\n",
      "        features.append(_sum_of_gaussians(x_range, spectrum['freq'], intensities, kernel_width))\n",
      "        molnames.append(int(molid))\n",
      "        \n",
      "    feat_name = ['%sband%d_%d'%(spec_type,kernel_width,x) for x in x_range]\n",
      "    \n",
      "    features = ds.FeatureBank(feat_name, molnames, np.array(features))\n",
      "    return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Function to load csv descriptor file"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "required format: Each row contains feature values of a molecule. First row contains feature names. First column contains molecule id, second column gets skipped."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_feature(filename, filter_func=None, verbose=False):\n",
      "    ''' read in feature from csv file, return FeatureBank instance'''\n",
      "    descname = csv.reader(open(filename), delimiter=',').next()[2:]\n",
      "    desc = np.genfromtxt(filename,  usecols=range(2,len(descname)+2), delimiter=',', skip_header=1)\n",
      "    molid = np.genfromtxt(filename,  usecols=range(0,1), delimiter=',', skip_header=1, dtype=int)\n",
      "    if filter_func:\n",
      "        mask = np.sum(filter_func(desc),1) == 0\n",
      "        desc = desc[mask]\n",
      "        if verbose: print 'removed mols ', [molid[i] for i in np.where(mask==False)[0]]\n",
      "        molid = molid[mask]        \n",
      "    return ds.FeatureBank(descname, molid, desc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def condense_list_dict(dic, reducefct=np.mean):\n",
      "    ''' apply reducefct to every value of dictionary'''\n",
      "    reduced_dict = {}\n",
      "    for k, v in dic.items():\n",
      "        reduced_dict[k] = reducefct(v)\n",
      "    return reduced_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Function to calculate distances in chemical space"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Distance as overlap of support vector models"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sv_overlap(svm1, svm2, extension = 1):\n",
      "    ''' calculates collective covered area for two support vector models'''\n",
      "    ind_overlaps = []\n",
      "    for ind1, sv1 in enumerate(svm1.support_vectors_):\n",
      "        for ind2, sv2 in enumerate(svm2.support_vectors_):\n",
      "            gamma = 1./svm1.support_vectors_.shape[1]          \n",
      "            integral = np.exp(-0.5*gamma*extension*np.sum((sv1-sv2)**2))\n",
      "            overlap = svm1.dual_coef_[:,ind1] * svm2.dual_coef_[:,ind2]*integral\n",
      "            ind_overlaps.append(overlap)\n",
      "    return np.sum(ind_overlaps)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Distance as weighted chemspace distance for all coactive molecules"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def neighbourness(spec1, spec2, chemspace_dist):\n",
      "    ''' weighted sum of chemspace distances of coactive molecules'''\n",
      "    response_overlap = np.outer(spec1, spec2)\n",
      "    response_overlap /= np.sum(response_overlap)\n",
      "    neighbourness = np.sum(response_overlap*chemspace_dist)\n",
      "    return neighbourness"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Class to create scatterplots with interactive labelling"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class AnnotationAxes:\n",
      "    def __init__(self, ax):\n",
      "        self.ax = ax\n",
      "        self.labels = {}\n",
      "        ax.get_figure().canvas.mpl_connect('pick_event', self.onpick)\n",
      "        \n",
      "    def onpick(self, event):\n",
      "        self.ax.text(event.mouseevent.xdata, event.mouseevent.ydata, self.labels[event.artist])\n",
      "       \n",
      "        plt.draw()\n",
      "        \n",
      "    def scatter(self, x, y, annotation, **kwargs):\n",
      "        for xval, yval, text in zip(x,y,annotation):\n",
      "            handle = ax.scatter(xval, yval, picker=True, **kwargs)\n",
      "            self.labels[handle] = text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Read in Feature and Data"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Specify parameter"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "basepath = os.path.join('/home/jan/Dokumente/MOBData')\n",
      "descriptorpath = os.path.join(basepath, 'ChemBase', 'odors_dez2013')\n",
      "vibpath = os.path.join(basepath, 'ChemBase', 'odors_dez2013', 'Vib')\n",
      "fullMOR182spec_file = os.path.join(basepath, 'DataDicts', 'MOR18-2spec.json')\n",
      "cas2molid_file = os.path.join(basepath, 'ChemBase','odors_dez2013','cas2molid.csv')\n",
      "cas2name_file = os.path.join(basepath, 'DataDicts', 'Name2MomCas.tab')\n",
      "savepath = os.path.join(basepath, 'Vis', 'ChemSpace')\n",
      "bg_path = os.path.join(basepath, 'MOBconverted')\n",
      "fingerprinted_specfile = os.path.join(basepath, 'DataDicts', \n",
      "                                      'spectra_correlation_average_nnmf_150_sm2_convex_sp*_ios_meas', 'ts')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Create mapping CAS to molecule ID"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If CAS is ambiguous (enatiomeres), only one instance is picked"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cas2molid = {l[0]:l[1] for l in csv.reader(open(cas2molid_file))}\n",
      "cas2name = {l[0]:l[1] for l in csv.reader(open(cas2name_file),  delimiter='\\t')}\n",
      "molid2name = {v:cas2name[k] for k,v in cas2molid.items() if k in cas2name}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load complete feature pickle (skip the following steps)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "featurespaces = pickle.load(open(os.path.join(basepath, 'DataDicts','fspaces.pik')))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "eDragon Features"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "read in all eDragon features. Exclude molecules with errors (feature value = -999). Skip Features in list 'skip' (as for those too many molecules exibit errors)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "featurespaces = {}\n",
      "skip = ['INFORMATION_INDICES']\n",
      "filter_func = lambda x: np.logical_or(np.isnan(x), x==-999)\n",
      "\n",
      "all_featgroups = {}\n",
      "filenames = glob.glob(os.path.join(descriptorpath, 'eDragon', '*.csv'))\n",
      "for filename in filenames:\n",
      "    name = os.path.basename(filename).split('.')[0]    \n",
      "    if name in skip:\n",
      "        continue\n",
      "    feat = load_feature(filename, filter_func)\n",
      "    all_featgroups[name] = feat\n",
      "featurespaces.update(all_featgroups)\n",
      "featurespaces['edragon_all'] = ds.combine_features(all_featgroups.values())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Haddad, Saito and simple IJC features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "featurespaces['haddad'] = load_feature(os.path.join(descriptorpath, 'haddad_desc.csv'), filter_func)\n",
      "featurespaces['saito'] = load_feature(os.path.join(descriptorpath, 'saito_desc.csv'), filter_func)\n",
      "featurespaces['ijc'] = load_feature(os.path.join(descriptorpath, 'ijc_shape.csv'), filter_func)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "EVA feature variants"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "create EVA features (and those scaled by ir respectivly raman intensity) for different kernel widths. Sampling steps are choosen equal to kernel width. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kernel_widths = [1, 5, 10, 20, 50, 100, 200] \n",
      "vib = pickle.load(open(os.path.join(vibpath, 'freq.pckl')))\n",
      "for k in kernel_widths:  \n",
      "    eva = calc_eva(vib, bin_width=k, kernel_width=k)\n",
      "    ir = calc_eva(vib, 'ir', bin_width=k, kernel_width=k)\n",
      "    raman = calc_eva(vib, 'raman', bin_width=k, kernel_width=k)\n",
      "    featurespaces['eva%03d'%k]=eva\n",
      "    featurespaces['ir%03d'%k]=ir\n",
      "    featurespaces['raman%03d'%k]=raman"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "hierachical combine kernel widths"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "combi = [10, 20, 50, 100, 200]\n",
      "\n",
      "featurespaces['eva_hcombi'] = ds.combine_features([featurespaces['eva%03d'%k] for k in combi])\n",
      "featurespaces['ir_hcombi'] = ds.combine_features([featurespaces['ir%03d'%k] for k in combi])\n",
      "featurespaces['raman_hcombi'] = ds.combine_features([featurespaces['raman%03d'%k] for k in combi])\n",
      "\n",
      "featurespaces['eva_all'] = ds.combine_features([featurespaces['eva%03d'%k] for k in [1,5,10,20,50,100,200]])\n",
      "featurespaces['ir_all'] = ds.combine_features([featurespaces['ir%03d'%k] for k in [1,5,10,20,50,100,200]])\n",
      "featurespaces['raman_all'] = ds.combine_features([featurespaces['raman%03d'%k] for k in [1,5,10,20,50,100,200]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "create featureset combinations"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "combi_feat = {\n",
      "    #'all': ds.combine_features([featurespaces[name] for name in ['edragon_all', 'eva_hcombi', 'ir_hcombi', 'raman_hcombi']]),\n",
      "    'edragon-ircombi': ds.combine_features([featurespaces[name] for name in ['edragon_all', 'ir_hcombi']]),\n",
      "    'edragon-evacombi': ds.combine_features([featurespaces[name] for name in ['edragon_all', 'eva_hcombi']]),\n",
      "    'edragon-eva10': ds.combine_features([featurespaces[name] for name in ['edragon_all', 'eva010']]),\n",
      "    'edragon-eva1': ds.combine_features([featurespaces[name] for name in ['edragon_all', 'eva001']]),\n",
      "    'edragon-eva5': ds.combine_features([featurespaces[name] for name in ['edragon_all', 'eva005']]),\n",
      "    'edragon-ir10': ds.combine_features([featurespaces[name] for name in ['edragon_all', 'ir010']]),\n",
      "    }\n",
      "featurespaces.update(combi_feat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Save all features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "save = False\n",
      "if save: \n",
      "    pickle.dump(featurespaces, open(os.path.join(basepath, 'DataDicts','fspaces.pik'),'w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Full MOR18-2 spectrum"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "method = 'nnmf_200_sm2_convex_negTimelowSP_sp*_ios_measnormed'\n",
      "aggregate = np.mean\n",
      "\n",
      "spec = json.load(open(fullMOR182spec_file))\n",
      "mor182_spec_temp = condense_list_dict(spec[method], aggregate)\n",
      "mor182_spec = {}\n",
      "for k, v in mor182_spec_temp.items():\n",
      "    k = k.strip()\n",
      "    if k in cas2molid:\n",
      "        mor182_spec[int(cas2molid[k])]=v\n",
      "    elif len(k.split('_')) == 1:\n",
      "        logger.warning('no molid found for %s'%k)\n",
      "    else:\n",
      "        logger.debug('no molid found for %s'%k)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:root:no molid found for EA - GEO\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:root:no molid found for MP - GEO\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:root:no molid found for Anisole - GEO\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:root:no molid found for 2M2P-EA\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:root:no molid found for MP-EA\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:root:no molid found for Blood A\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:root:no molid found for 2M2P - GEO\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:root:no molid found for Blood B\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:root:no molid found for Anisole-EA\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Fingerprinted Spectra"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load fingerprinted spectra and convert to dictionary"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fp_spec = ia.TimeSeries()\n",
      "fp_spec.load(fingerprinted_specfile)\n",
      "spec_dict = defaultdict(dict)\n",
      "for clust_id, clust in enumerate(fp_spec.label_objects):\n",
      "    for v, k in zip(fp_spec._series[:,clust_id], fp_spec.label_stimuli):\n",
      "        k = k.strip()\n",
      "        if k in cas2molid:\n",
      "            spec_dict[clust][int(cas2molid[k])]=v\n",
      "        else:\n",
      "            logger.info('no molid found for %s'%k)   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Prediction Models"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Show difference in featurespace between ligands and nonligands for MOR18-2"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "what = 'eva001'\n",
      "zscore = False\n",
      "\n",
      "mols = mor182_spec.keys()\n",
      "ligands = [mols[i] for i in np.argsort(mor182_spec.values())[-10:]]\n",
      "non_ligands = [mols[i] for i in np.argsort(mor182_spec.values())[:150]]\n",
      "feat = copy.copy(featurespaces[what])\n",
      "if zscore: feat.zscore()\n",
      "\n",
      "ligand_vib = np.percentile(feat.data[[feat.obj_name.index(i) for i in ligands if i in feat.obj_name]],\n",
      "                           [0,25,50,75,100], axis=0)\n",
      "nonligand_vib = np.percentile(feat.data[[feat.obj_name.index(i) for i in non_ligands if i in feat.obj_name]],\n",
      "                           [0,25,50,75,100], axis=0)\n",
      "\n",
      "# plot\n",
      "plt.plot(ligand_vib[2], 'g', label='median (min-max) ligands')\n",
      "plt.fill_between(range(feat.data.shape[1]), ligand_vib[0], ligand_vib[-1], alpha=0.2, color='g')\n",
      "plt.plot(nonligand_vib[2], 'r', label='median (min-max) non-ligands')\n",
      "plt.fill_between(range(feat.data.shape[1]), nonligand_vib[0], nonligand_vib[-1], alpha=0.2, color='r')\n",
      "plt.ylabel('activation')\n",
      "plt.xlabel('feature')\n",
      "plt.title(what)\n",
      "plt.legend()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 111
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Single Feature Relevance"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Define Pyramid regression model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class PyramidRegression():\n",
      "\n",
      "    def __init__(self):\n",
      "        self.zenith = None\n",
      "        self.ir1 = None\n",
      "        self.ir2 = None\n",
      "        \n",
      "    def fit(self,x,y):\n",
      "        \n",
      "        ir1 = extIsotonicRegression()\n",
      "        ir2 = extIsotonicRegression(increasing=False)\n",
      "        \n",
      "        order = np.argsort(x)\n",
      "        x = x[order]\n",
      "        y = y[order]\n",
      "        \n",
      "        se_list = []     \n",
      "        se_list.append(np.sum((y-ir1.fit_transform(x,y))**2))\n",
      "        for i in range(1,len(x)-1):\n",
      "            y1 = ir1.fit_transform(x[:i],y[:i])\n",
      "            y2 = ir2.fit_transform(x[i:],y[i:])\n",
      "            se_list.append(np.sum((y[:i]-y1)**2)+np.sum((y[i:]-y2)**2))\n",
      "        se_list.append(np.sum((y-ir2.fit_transform(x,y))**2))\n",
      "        self.turnpoint = np.argmin(se_list)\n",
      "        self.zenith = x[self.turnpoint]\n",
      "        self.X_ = x\n",
      "        # refit with best parameter\n",
      "        yhat1, yhat2 = [], []\n",
      "        if self.turnpoint>0:\n",
      "            self.ir1 = extIsotonicRegression()\n",
      "            yhat1 = self.ir1.fit_transform(x[:self.turnpoint],y[:self.turnpoint])            \n",
      "        if self.turnpoint<(len(x)-1):\n",
      "            self.ir2 = extIsotonicRegression(increasing=False)\n",
      "            yhat2 = self.ir2.fit_transform(x[self.turnpoint:],y[self.turnpoint:])\n",
      "        self.r2 = r2_score(y, np.hstack([yhat1, yhat2]))\n",
      "\n",
      "     \n",
      "    def transform(self,x):\n",
      "        out = np.zeros(x.shape)\n",
      "        mask_raise = x<self.zenith\n",
      "        mask_fall = x>=self.zenith              \n",
      "        if np.sum(mask_raise)>0:\n",
      "            out[mask_raise] = self.ir1.transform(x[mask_raise])\n",
      "        if np.sum(mask_fall)>0:\n",
      "            out[mask_fall] = self.ir2.transform(x[mask_fall])\n",
      "        return out\n",
      "    \n",
      "    def predict(self, x):\n",
      "        return self.transform(x)\n",
      "\n",
      "class extIsotonicRegression(IsotonicRegression):\n",
      "    \n",
      "    def __init__(self, **kwargs):\n",
      "        super(extIsotonicRegression, self).__init__(**kwargs)\n",
      "        \n",
      "    def transform(self, x):\n",
      "        xtemp =  x.copy()\n",
      "        xmin,xmax = np.min(self.X_), np.max(self.X_)\n",
      "        xtemp[xtemp<xmin]=xmin\n",
      "        xtemp[xtemp>xmax]=xmax\n",
      "        return super(extIsotonicRegression, self).transform(xtemp)\n",
      "    \n",
      "    def predict(self, x):\n",
      "        return self.transform(x)\n",
      "\n",
      "# Feature selection score functions\n",
      "def pyramid_score(X,y):\n",
      "    r2 = []\n",
      "    for x in X.T:\n",
      "        py_reg = PyramidRegression()\n",
      "        py_reg.fit(x+np.random.randn(len(x))*1E-7, y)\n",
      "        r2.append(py_reg.r2) \n",
      "    return np.array(r2), None\n",
      "\n",
      "def myfclassify(X,y, thres=0.5):\n",
      "    return f_classif((X>thres).astype('int'), y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Result collectors"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainsets = {}\n",
      "r2 = {}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Evaluate monotonic regression models (linear, isotonic)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r2['monoincrease'] = defaultdict(list)\n",
      "r2['monodecrease'] = defaultdict(list)\n",
      "r2['linear'] = defaultdict(list)\n",
      "keys = ['edragon_all', 'eva_all', 'ir_all', 'raman_all', 'ijc']\n",
      "for k in keys:\n",
      "    feature = copy.deepcopy(featurespaces[k])\n",
      "    trainsets[k] = ds.TrainData(mor182_spec, feature)\n",
      "    y = trainsets[k].targets\n",
      "    for i, single_feat in enumerate(trainsets[k].features.T):\n",
      "        x = single_feat.copy()+np.random.randn(len(single_feat))*1E-5\n",
      "        ir_reg = IsotonicRegression()\n",
      "        yhat = ir_reg.fit_transform(x, y)\n",
      "        r2['monoincrease'][k].append(r2_score(y, yhat))\n",
      "        \n",
      "        ir_reg = IsotonicRegression(increasing=False)\n",
      "        yhat = ir_reg.fit_transform(x, y)\n",
      "        r2['monodecrease'][k].append(r2_score(y, yhat))\n",
      "        \n",
      "        x = x.reshape((-1,1))\n",
      "        lin_reg = LinearRegression()\n",
      "        lin_reg.fit(x, y)\n",
      "        yhat = lin_reg.predict(x)\n",
      "        r2['linear'][k].append(r2_score(y, yhat))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Evaluate pyramid regression models"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "keys = ['edragon_all', 'ijc', 'eva_all']\n",
      "for k in keys:\n",
      "    r2['pyramid'][k] = []\n",
      "    feature = copy.deepcopy(featurespaces[k])\n",
      "    trainsets[k] = ds.TrainData(mor182_spec, feature)\n",
      "    y = trainsets[k].targets\n",
      "    for i, single_feat in enumerate(trainsets[k].features.T):\n",
      "        x = single_feat.copy()+np.random.randn(len(single_feat))*1E-5\n",
      "        py_reg = PyramidRegression()\n",
      "        py_reg.fit(x, y)\n",
      "        r2['pyramid'][k].append(py_reg.r2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Print best r2 score for different featurespaces"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for m in ['linear', 'monoincrease', 'monodecrease', 'pyramid']: \n",
      "    print '========== %s =========='%m\n",
      "    for k in ['ijc', 'edragon_all', 'eva_all']:\n",
      "        i = np.argmax(r2[m][k])\n",
      "        print k, [trainsets[k].feat_name[i]], r2[m][k][i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "========== linear ==========\n",
        "ijc ['CAtoms'] 0.0495136897061\n",
        "edragon_all ['BEHp1'] 0.13610209531\n",
        "eva_all ['pureband1_1812'] 0.20285678305\n",
        "========== monoincrease ==========\n",
        "ijc ['VP ACD mmHG25'] 0.225366037079\n",
        "edragon_all ['E1u'] 0.237491751783\n",
        "eva_all ['pureband1_1813'] 0.303431689547\n",
        "========== monodecrease ==========\n",
        "ijc ['CAtoms'] 0.148484695821\n",
        "edragon_all ['ATS2p'] 0.287400195761\n",
        "eva_all ['pureband5_400'] 0.278583191362\n",
        "========== pyramid ==========\n",
        "ijc ['VP ACD mmHG25'] 0.296287274242\n",
        "edragon_all ['ESpm15r'] 0.414083632793\n",
        "eva_all ['pureband5_1820'] 0.502378898385\n"
       ]
      }
     ],
     "prompt_number": 330
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "SVR with feature selection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "featnum = [1,2,4,8,16, 32,64,128, 256, 512]\n",
      "k = 'edragon-eva5'\n",
      "slection_func = myfclassify #pyramid_score\n",
      "\n",
      "feature = copy.deepcopy(featurespaces[k])\n",
      "feature.zscore()\n",
      "trainset = ds.TrainData(mor182_spec, feature)\n",
      "\n",
      "for num in featnum:    \n",
      "    estimator_class = bp.BootstrapRegressor\n",
      "    estimator_param ={'regressor':bp.FilteredRegressor, \n",
      "                      'reg_param':{'regressor': NuSVR, 'reg_param':{'C':0.9},\n",
      "                                   'filtering':SelectKBest, 'filt_param':{'score_func':selection_func, 'k':num}}, \n",
      "                      'n_member':20, 'strat_thres':0.5}\n",
      "    estimator = estimator_class(**estimator_param) \n",
      "    estimator.fit(trainset.features, trainset.targets)\n",
      "    print '%d: %.2f, %.2f'%(num, estimator.oob_score_single, estimator.oob_score_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fit 0\n",
        "1: -0.04, -0.03"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "fit 0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2: -0.01, 0.00"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "fit 0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4: 0.04, 0.08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "fit 0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8: 0.03, 0.08"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "fit 0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16: 0.08, 0.17"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "fit 0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "32: 0.10, 0.20"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "fit 0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "64: 0.14, 0.27"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "fit 0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "128: 0.15, 0.27"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "fit 0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "256: 0.27, 0.36"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "fit 0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "512: 0.26, 0.34"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "MOR18-2 prediction for different Featurespaces"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Fit SVR models on bootstrap samples for validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# remove some featspace to save memory\n",
      "[featurespaces.pop(k) for k in featurespaces.keys() if (('raman' in k) or ('ir' in k))]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "36\n"
       ]
      }
     ],
     "prompt_number": 274
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "remove = [140, 1016, 92, 164, 1000, 239, 1012, 312] #molecules with no features in some featurespace\n",
      "mor182_spec_clean = copy.deepcopy(mor182_spec)\n",
      "[mor182_spec_clean.pop(i) for i in remove]\n",
      "models_mor182 = {}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "to_evaluate = featurespaces\n",
      "estimator_class = bp.BootstrapRegressor\n",
      "estimator_param ={'regressor': SVR, 'reg_param':{'C':5, 'epsilon':0.1}, 'n_member':50, 'strat_thres':2}\n",
      "\n",
      "for ix, featspace in enumerate(to_evaluate):\n",
      "    feature = copy.deepcopy(to_evaluate[featspace])\n",
      "    feature.zscore()\n",
      "    mytrain = ds.TrainData(mor182_spec, feature)\n",
      "    estimator = estimator_class(**estimator_param) \n",
      "    estimator.fit(mytrain.features, mytrain.targets)\n",
      "    models_mor182[featspace] = (estimator, mytrain)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fit 0\n",
        "fit 0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "fit 0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Plot model performance of feature spaces"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "toplot = models_mor182.keys()\n",
      "performance = np.array([models_mor182[k][0].oob_score_single for k in toplot])\n",
      "order = np.argsort(performance)\n",
      "\n",
      "fig = plt.figure()\n",
      "ax = fig.add_axes([0.15,0.35,0.8,0.6])\n",
      "x = np.arange(performance.size)\n",
      "ax.bar(x, np.sort(performance))\n",
      "ax.set_xticks(x+0.5)\n",
      "ax.set_xticklabels([toplot[i] for i in order], rotation='45', ha='right', size=8)\n",
      "ax.set_ylabel('r2')\n",
      "plt.show()\n",
      "\n",
      "fig.savefig(os.path.join(savepath, 'featspac_performance.pdf'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Bootstrap prediction vs. target plot "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Click on scatterpoints to display odor name"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model, traindata = models_mor182['edragon-eva10']\n",
      "\n",
      "fig = plt.figure()\n",
      "ax = fig.add_subplot(111)\n",
      "aax = AnnotationAxes(ax)\n",
      "\n",
      "annotations = [molid2name[str(i)] if str(i) in molid2name else '' for i in traindata.obj_name]\n",
      "\n",
      "std =  [np.std(model._pred_dict[mol]) for mol in model._train_targets.keys()]\n",
      "aax.scatter(model._train_targets.values(), model.oob_prediction, \n",
      "            annotations, facecolors='0.5', alpha=0.5, edgecolors='none')\n",
      "ax.errorbar(model._train_targets.values(), model.oob_prediction, yerr=std, \n",
      "            fmt=None, ecolor='0.5')\n",
      "ax.set_xlabel('bootstrap prediction')\n",
      "ax.set_ylabel('target')\n",
      "\n",
      "plt.plot([0,1], [0,1], 'k:')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 310
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Prediction for fingerprinted spectra"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Fit SVR models on bootstrap samples for validation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat = copy.deepcopy(combi_feat['edragon-eva5'])\n",
      "feat.zscore()\n",
      "estimator_class = bp.BootstrapRegressor\n",
      "estimator_param ={'regressor': NuSVR, 'reg_param':{'C':10}, 'n_member':50, 'strat_thres':2}\n",
      "\n",
      "models_fingerprinted = {}\n",
      "\n",
      "for clustid in spec_dict: \n",
      "    spec_data = spec_dict[clustid]\n",
      "    mytrain = ds.TrainData(spec_data, feat)\n",
      "    estimator = estimator_class(**estimator_param) \n",
      "    estimator.fit(mytrain.features, mytrain.targets)\n",
      "    models_fingerprinted[clustid] = (estimator, mytrain)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Show prediction quality for different spectra"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "performance = np.array([i[0].oob_score_single for i in models_fingerprinted.values()])\n",
      "order = np.argsort(performance)\n",
      "\n",
      "fig = plt.figure()\n",
      "ax = fig.add_axes([0.15,0.35,0.8,0.6])\n",
      "x = np.arange(performance.size)\n",
      "ax.bar(x, np.sort(performance))\n",
      "ax.set_xticks(x+0.5)\n",
      "ax.set_xticklabels([models_fingerprinted.keys()[i] for i in order], rotation='45', ha='right', size=8)\n",
      "ax.set_ylabel('r2')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Bootstrap prediction vs. target plot "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clustid = 'clust_362'\n",
      "model, traindata = models_fingerprinted[clustid]\n",
      "\n",
      "fig = plt.figure()\n",
      "ax = fig.add_subplot(111)\n",
      "aax = AnnotationAxes(ax)\n",
      "\n",
      "annotations = [molid2name[str(i)].decode('utf-8') if str(i) in molid2name else '' for i in traindata.obj_name]\n",
      "x = model._train_targets.values()\n",
      "y = model.oob_prediction #odel.full_regressor.predict(traindata.features) #\n",
      "std =  [np.std(model._pred_dict[mol]) for mol in model._train_targets.keys()]\n",
      "\n",
      "aax.scatter(x, y, annotations, facecolors='k')\n",
      "ax.errorbar(x, y, yerr=std, fmt=None, ecolor='k')\n",
      "ax.set_xlabel('bootstrap prediction')\n",
      "ax.set_ylabel('target')\n",
      "\n",
      "plt.plot([0,0.5], [0,0.5], 'k:')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Distance of MOR18-2 to other fingerprinted spectra"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat = copy.deepcopy(featurespaces['edragon-eva5'])\n",
      "feat.zscore()\n",
      "\n",
      "traindata = ds.TrainData(spec_dict['clust_200'], feat)\n",
      "rbf_dist = pdist(traindata.features, 'euclidean') #lambda u,v: 1-np.exp(-((u-v)**2).sum()/traindata.features.shape[1]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 95
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Calculate weighted distance of coactive molecules "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reference = 'clust_200'\n",
      "rand = np.abs(np.random.randn(44)*1E-10)\n",
      "spec1 = [spec_dict[reference][i] for i in traindata.obj_name]+rand\n",
      "\n",
      "overlaps = {} \n",
      "for k  in spec_dict:\n",
      "    spec2 = [spec_dict[k][i] for i in traindata.obj_name]+rand\n",
      "    overlaps[k] = neighbourness(spec1, spec2, squareform(rbf_dist))\n",
      "mycmap = plt.cm.RdYlGn_r\n",
      "sortedval = np.sort(overlaps.values())\n",
      "distmin, distmax = sortedval[4], sortedval[-5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "or calculate overlap of SVR models"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reference = 'clust_200'\n",
      "svr1 = models_fingerprinted[reference][0].full_regressor\n",
      "\n",
      "overlaps = {} \n",
      "for k, (model, traindata) in models_fingerprinted.items():\n",
      "    overlaps[k] = sv_overlap(svr1, model.full_regressor, 1)\n",
      "mycmap = plt.cm.RdYlGn\n",
      "sortedval = np.sort(overlaps.values())\n",
      "distmin, distmax = sortedval[1], sortedval[-3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Visualization of chemical similarity"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "load bg images"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "animals = ['111210sph', '111221sph', '111222sph', '120107', '120119', '120121', '120125']\n",
      "turn = ['111222sph', '120119', '120121'] #turn if left bulb\n",
      "bg_list = [plt.imread(os.path.join(bg_path, measID, 'bg.png')) for measID in animals]\n",
      "for ani in turn:\n",
      "    bg_list[animals.index(ani)] = bg_list[animals.index(ani)][::-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IOError",
       "evalue": "[Errno 2] No such file or directory: '/home/jan/Dokumente/MOBData/MOBconverted/111210sph/bg.png'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-23-5fbf4669f2fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0manimals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'111210sph'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'111221sph'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'111222sph'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'120107'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'120119'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'120121'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'120125'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mturn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'111222sph'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'120119'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'120121'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#turn if left bulb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mbg_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbg_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeasID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bg.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmeasID\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manimals\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mani\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mturn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbg_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0manimals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mani\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbg_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0manimals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mani\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/jan/virtualenvs/standard/local/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mimread\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2175\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_dedent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_imread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2176\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2177\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_imread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/jan/virtualenvs/standard/local/lib/python2.7/site-packages/matplotlib/image.pyc\u001b[0m in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   1253\u001b[0m     \u001b[1;31m# tricky in C.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_string_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1255\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1256\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1257\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/home/jan/Dokumente/MOBData/MOBconverted/111210sph/bg.png'"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "plot chemical distance to MOR18-2"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(15,7))\n",
      "axes= [fig.add_subplot(2,4,i+1) for i in range(7)]\n",
      "\n",
      "'''\n",
      "for i, ax in enumerate(axes):\n",
      "    ax.imshow(bg_list[i], interpolation='none', cmap=plt.cm.bone, extent=[0,84,64,0])\n",
      "    ax.set_axis_off()\n",
      "'''\n",
      "\n",
      "for clust_num, clust in enumerate(fp_spec.label_objects):\n",
      "    dist = (overlaps[clust]-distmin)/(distmax-distmin)\n",
      "    for ind, base in enumerate(fp_spec.base.objects_sample(clust_num)):\n",
      "        axes[ind].contourf(base, [0.5,2], colors=[mycmap(dist)])\n",
      "for ind, base in enumerate(fp_spec.base.objects_sample(fp_spec.label_objects.index(reference))):\n",
      "    axes[ind].contour(base, [0.5], colors=['m'])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Spectral embedding of receptive Fields in chemical Space"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "spt_nbor = ['clust_%d'%i for i in [200,250,211,172,300,264,257,292,261,131,146,62]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat = copy.deepcopy(featurespaces['edragon-eva5'])\n",
      "feat.zscore()\n",
      "\n",
      "traindata = ds.TrainData(spec_dict['clust_200'], feat)\n",
      "rbf_dist = pdist(traindata.features, 'euclidean') #lambda u,v: 1-np.exp(-((u-v)**2).sum()/traindata.features.shape[1]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "embedding = MDS(dissimilarity='precomputed', n_components=2, random_state=1)\n",
      "out = embedding.fit_transform(squareform(rbf_dist))\n",
      "\n",
      "fig = plt.figure()\n",
      "for ind, k in  enumerate(spt_nbor): #enumerate(spec_dict):\n",
      "    ax = fig.add_subplot(7, 7, ind+1)\n",
      "    data = spec_dict[k]\n",
      "    norm = np.max(data.values())\n",
      "    ax.scatter(out[:,0], out[:,1], s=20, linewidths=1,\n",
      "                facecolor= [plt.cm.Greens(data[i]/norm) for i in traindata.obj_name],\n",
      "                edgecolor= '0.8', alpha=0.8)\n",
      "    ax.set_xticks([])\n",
      "    ax.set_yticks([])\n",
      "    ax.set_title(k)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 108
    }
   ],
   "metadata": {}
  }
 ]
}